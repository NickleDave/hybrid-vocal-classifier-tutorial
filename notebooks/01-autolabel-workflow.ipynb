{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. hybrid-vocal-classifier autolabel workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the steps in the workflow for autolabeling vocalizations.\n",
    "\n",
    "First we import the library, since in Python you need to `import` a library before you can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvc  # in Python we have to import a library before we can use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Label a small set of songs to provide **training data** for the models, typically ~20 songs.\n",
    "Here we download the data from a repository.  \n",
    "** You don't need to run this if you've already downloaded the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvc.utils.fetch('gy6or6.032212')\n",
    "hvc.utils.fetch('gy6or6.032612')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pick a machine learning algorithm/**model** and the **features** used to train the model. \n",
    "\n",
    "In this case we'll use the k-Nearest Neighbors (k-NN) algorithm because it's fast to apply to our data. We'll use the features built into the library that have been tested with k-NN.\n",
    "\n",
    "Picking a model and the features that go with it is simple:  \n",
    "1. In a text editor, open `gy6or6_autolabel.example.knn.extract.config.yml`\n",
    "2. Below the line that says `feature group:` add `knn` after the dash.\n",
    "3. Below the line that says `data_dirs:` add the path to the data you downloaded after the dash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract features for that model from song files that will be used to train the model.  \n",
    "\n",
    "We call the `extract` function and we pass it the name of the `yaml` config file as an argument.\n",
    "\n",
    "```Python\n",
    "# 1. pick a model and 2. extract features for that model\n",
    "# Model and features are defined in extract.config.yml file.\n",
    "hvc.extract('gy6or6_autolabel.example.extract.knn.config.yml')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed extract config.\n",
      "Completing item 1 of 1 in to-do list\n",
      "Changing to data directory: /home/ildefonso/Documents/data/gy6or6/032312/\n",
      "Processing audio file 1 of 162.\n",
      "Processing audio file 2 of 162.\n",
      "Processing audio file 3 of 162.\n",
      "Processing audio file 4 of 162.\n",
      "Processing audio file 5 of 162.\n",
      "Processing audio file 6 of 162.\n",
      "Processing audio file 7 of 162.\n",
      "Processing audio file 8 of 162.\n",
      "Processing audio file 9 of 162.\n",
      "Processing audio file 10 of 162.\n",
      "Processing audio file 11 of 162.\n",
      "Processing audio file 12 of 162.\n",
      "Processing audio file 13 of 162.\n",
      "Processing audio file 14 of 162.\n",
      "Processing audio file 15 of 162.\n",
      "Processing audio file 16 of 162.\n",
      "Processing audio file 17 of 162.\n",
      "Processing audio file 18 of 162.\n",
      "Processing audio file 19 of 162.\n",
      "Processing audio file 20 of 162.\n",
      "Processing audio file 21 of 162.\n",
      "Processing audio file 22 of 162.\n",
      "Processing audio file 23 of 162.\n",
      "Processing audio file 24 of 162.\n",
      "Processing audio file 25 of 162.\n",
      "Processing audio file 26 of 162.\n",
      "Processing audio file 27 of 162.\n",
      "Processing audio file 28 of 162.\n",
      "Processing audio file 29 of 162.\n",
      "Processing audio file 30 of 162.\n",
      "Processing audio file 31 of 162.\n",
      "Processing audio file 32 of 162.\n",
      "Processing audio file 33 of 162.\n",
      "Processing audio file 34 of 162.\n",
      "Processing audio file 35 of 162.\n",
      "Processing audio file 36 of 162.\n",
      "Processing audio file 37 of 162.\n",
      "Processing audio file 38 of 162.\n",
      "Processing audio file 39 of 162.\n",
      "Processing audio file 40 of 162.\n",
      "Processing audio file 41 of 162.\n",
      "Processing audio file 42 of 162.\n",
      "Processing audio file 43 of 162.\n",
      "Processing audio file 44 of 162.\n",
      "Processing audio file 45 of 162.\n",
      "Processing audio file 46 of 162.\n",
      "Processing audio file 47 of 162.\n",
      "Processing audio file 48 of 162.\n",
      "Processing audio file 49 of 162.\n",
      "Processing audio file 50 of 162.\n",
      "Processing audio file 51 of 162.\n",
      "Processing audio file 52 of 162.\n",
      "Processing audio file 53 of 162.\n",
      "Processing audio file 54 of 162.\n",
      "Processing audio file 55 of 162.\n",
      "Processing audio file 56 of 162.\n",
      "Processing audio file 57 of 162.\n",
      "Processing audio file 58 of 162.\n",
      "Processing audio file 59 of 162.\n",
      "Processing audio file 60 of 162.\n",
      "Processing audio file 61 of 162.\n",
      "Processing audio file 62 of 162.\n",
      "Processing audio file 63 of 162.\n",
      "Processing audio file 64 of 162.\n",
      "Processing audio file 65 of 162.\n",
      "Processing audio file 66 of 162.\n",
      "Processing audio file 67 of 162.\n",
      "Processing audio file 68 of 162.\n",
      "Processing audio file 69 of 162.\n",
      "Processing audio file 70 of 162.\n",
      "Processing audio file 71 of 162.\n",
      "Processing audio file 72 of 162.\n",
      "Processing audio file 73 of 162.\n",
      "Processing audio file 74 of 162.\n",
      "Processing audio file 75 of 162.\n",
      "Processing audio file 76 of 162.\n",
      "Processing audio file 77 of 162.\n",
      "Processing audio file 78 of 162.\n",
      "Processing audio file 79 of 162.\n",
      "Processing audio file 80 of 162.\n",
      "Processing audio file 81 of 162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/anaconda3/envs/hvc-test/lib/python3.5/site-packages/hvc/features/extract.py:138: UserWarning: No labels in gy6or6_baseline_230312_1038.1203.cbin matched labels to use: ['i', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k']\n",
      "Did not extract features from file.\n",
      "  .format(filename, labels_to_use))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio file 82 of 162.\n",
      "Processing audio file 83 of 162.\n",
      "Processing audio file 84 of 162.\n",
      "Processing audio file 85 of 162.\n",
      "Processing audio file 86 of 162.\n",
      "Processing audio file 87 of 162.\n",
      "Processing audio file 88 of 162.\n",
      "Processing audio file 89 of 162.\n",
      "Processing audio file 90 of 162.\n",
      "Processing audio file 91 of 162.\n",
      "Processing audio file 92 of 162.\n",
      "Processing audio file 93 of 162.\n",
      "Processing audio file 94 of 162.\n",
      "Processing audio file 95 of 162.\n",
      "Processing audio file 96 of 162.\n",
      "Processing audio file 97 of 162.\n",
      "Processing audio file 98 of 162.\n",
      "Processing audio file 99 of 162.\n",
      "Processing audio file 100 of 162.\n",
      "Processing audio file 101 of 162.\n",
      "Processing audio file 102 of 162.\n",
      "Processing audio file 103 of 162.\n",
      "Processing audio file 104 of 162.\n",
      "Processing audio file 105 of 162.\n",
      "Processing audio file 106 of 162.\n",
      "Processing audio file 107 of 162.\n",
      "Processing audio file 108 of 162.\n",
      "Processing audio file 109 of 162.\n",
      "Processing audio file 110 of 162.\n",
      "Processing audio file 111 of 162.\n",
      "Processing audio file 112 of 162.\n",
      "Processing audio file 113 of 162.\n",
      "Processing audio file 114 of 162.\n",
      "Processing audio file 115 of 162.\n",
      "Processing audio file 116 of 162.\n",
      "Processing audio file 117 of 162.\n",
      "Processing audio file 118 of 162.\n",
      "Processing audio file 119 of 162.\n",
      "Processing audio file 120 of 162.\n",
      "Processing audio file 121 of 162.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/anaconda3/envs/hvc-test/lib/python3.5/site-packages/hvc/features/extract.py:138: UserWarning: No labels in gy6or6_baseline_230312_0918.584.cbin matched labels to use: ['i', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k']\n",
      "Did not extract features from file.\n",
      "  .format(filename, labels_to_use))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio file 122 of 162.\n",
      "Processing audio file 123 of 162.\n",
      "Processing audio file 124 of 162.\n",
      "Processing audio file 125 of 162.\n",
      "Processing audio file 126 of 162.\n",
      "Processing audio file 127 of 162.\n",
      "Processing audio file 128 of 162.\n",
      "Processing audio file 129 of 162.\n",
      "Processing audio file 130 of 162.\n",
      "Processing audio file 131 of 162.\n",
      "Processing audio file 132 of 162.\n",
      "Processing audio file 133 of 162.\n",
      "Processing audio file 134 of 162.\n",
      "Processing audio file 135 of 162.\n",
      "Processing audio file 136 of 162.\n",
      "Processing audio file 137 of 162.\n",
      "Processing audio file 138 of 162.\n",
      "Processing audio file 139 of 162.\n",
      "Processing audio file 140 of 162.\n",
      "Processing audio file 141 of 162.\n",
      "Processing audio file 142 of 162.\n",
      "Processing audio file 143 of 162.\n",
      "Processing audio file 144 of 162.\n",
      "Processing audio file 145 of 162.\n",
      "Processing audio file 146 of 162.\n",
      "Processing audio file 147 of 162.\n",
      "Processing audio file 148 of 162.\n",
      "Processing audio file 149 of 162.\n",
      "Processing audio file 150 of 162.\n",
      "Processing audio file 151 of 162.\n",
      "Processing audio file 152 of 162.\n",
      "Processing audio file 153 of 162.\n",
      "Processing audio file 154 of 162.\n",
      "Processing audio file 155 of 162.\n",
      "Processing audio file 156 of 162.\n",
      "Processing audio file 157 of 162.\n",
      "Processing audio file 158 of 162.\n",
      "Processing audio file 159 of 162.\n",
      "Processing audio file 160 of 162.\n",
      "Processing audio file 161 of 162.\n",
      "Processing audio file 162 of 162.\n",
      "making summary file\n"
     ]
    }
   ],
   "source": [
    "hvc.extract('gy6or6_autolabel.example.extract.knn.config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pick the **hyperparameters** used by the algorithm as it trains the model on the data.\n",
    "Now in Python we use some convenience functions to figure out which \"hyperparameters\" will give us the best accuracy when we train our machine learning models.\n",
    "```Python\n",
    "# 3. pick hyperparameters for model\n",
    "# Load summary feature file to use with helper functions for\n",
    "# finding best hyperparameters.\n",
    "from glob import glob\n",
    "summary_file = glob('./extract_output*/summary*')\n",
    "summary_data = hvc.load_feature_file(summary_file)\n",
    "# In this case, we picked a k-nearest neighbors model\n",
    "# and we want to find what value of k will give us the highest accuracy\n",
    "X = summary_data['features']\n",
    "y = summary_data['labels']\n",
    "cv_scores, best_k = hvc.utils.find_best_k(X,y,k_range=range(1, 11))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train, i.e., fit the **model** to the data  \n",
    "### 5. Select the **best** model based on some measure of accuracy. \n",
    "\n",
    "1. In a text editor, open `gy6or6_autolabel.example.knn.select.config.yml`\n",
    "2. On the line that says `feature_file:` paste the name of the feature file after the colon. The name will have a format like `summary_file_bird_ID_date`.\n",
    "\n",
    "Then run the following code in the cell below:\n",
    "```Python\n",
    "# 4. Fit the **model** to the data and 5. Select the **best** model\n",
    "hvc.select('gy6or6_autolabel.example.select.knn.config.yml')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gedit gy6or6_autolabel.example.select.knn.config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/Documents/repositories/talks_and_teaching/hybrid-vocal-classifier-tutorial\n"
     ]
    }
   ],
   "source": [
    "cd hybrid-vocal-classifier-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed select config.\n",
      "Completing item 1 of 1 in to-do list\n",
      "Training models with 50 samples, replicate #0\n",
      "training knn. fitting model. score on test set: 0.9080 , average accuracy on test set: 0.9011\n",
      "Training models with 50 samples, replicate #1\n",
      "training knn. fitting model. score on test set: 0.8780 , average accuracy on test set: 0.8689\n",
      "Training models with 50 samples, replicate #2\n",
      "training knn. fitting model. score on test set: 0.9120 , average accuracy on test set: 0.8995\n",
      "Training models with 50 samples, replicate #3\n",
      "training knn. fitting model. score on test set: 0.9760 , average accuracy on test set: 0.9747\n",
      "Training models with 50 samples, replicate #4\n",
      "training knn. fitting model. score on test set: 0.8620 , average accuracy on test set: 0.8512\n",
      "Training models with 50 samples, replicate #5\n",
      "training knn. fitting model. score on test set: 0.9300 , average accuracy on test set: 0.9284\n",
      "Training models with 50 samples, replicate #6\n",
      "training knn. fitting model. score on test set: 0.9140 , average accuracy on test set: 0.9088\n",
      "Training models with 50 samples, replicate #7\n",
      "training knn. fitting model. score on test set: 0.9700 , average accuracy on test set: 0.9723\n",
      "Training models with 50 samples, replicate #8\n",
      "training knn. fitting model. score on test set: 0.9160 , average accuracy on test set: 0.9100\n",
      "Training models with 50 samples, replicate #9\n",
      "training knn. fitting model. score on test set: 0.8660 , average accuracy on test set: 0.8531\n",
      "Training models with 100 samples, replicate #0\n",
      "training knn. fitting model. score on test set: 0.9560 , average accuracy on test set: 0.9445\n",
      "Training models with 100 samples, replicate #1\n",
      "training knn. fitting model. score on test set: 0.9800 , average accuracy on test set: 0.9824\n",
      "Training models with 100 samples, replicate #2\n",
      "training knn. fitting model. score on test set: 0.9860 , average accuracy on test set: 0.9828\n",
      "Training models with 100 samples, replicate #3\n",
      "training knn. fitting model. score on test set: 0.9720 , average accuracy on test set: 0.9714\n",
      "Training models with 100 samples, replicate #4\n",
      "training knn. fitting model. score on test set: 0.9800 , average accuracy on test set: 0.9763\n",
      "Training models with 100 samples, replicate #5\n",
      "training knn. fitting model. score on test set: 0.9740 , average accuracy on test set: 0.9763\n",
      "Training models with 100 samples, replicate #6\n",
      "training knn. fitting model. score on test set: 0.9640 , average accuracy on test set: 0.9710\n",
      "Training models with 100 samples, replicate #7\n",
      "training knn. fitting model. score on test set: 0.9620 , average accuracy on test set: 0.9476\n",
      "Training models with 100 samples, replicate #8\n",
      "training knn. fitting model. score on test set: 0.9400 , average accuracy on test set: 0.9266\n",
      "Training models with 100 samples, replicate #9\n",
      "training knn. fitting model. score on test set: 0.9660 , average accuracy on test set: 0.9646\n",
      "Training models with 150 samples, replicate #0\n",
      "training knn. fitting model. score on test set: 0.9900 , average accuracy on test set: 0.9919\n",
      "Training models with 150 samples, replicate #1\n",
      "training knn. fitting model. score on test set: 0.9820 , average accuracy on test set: 0.9816\n",
      "Training models with 150 samples, replicate #2\n",
      "training knn. fitting model. score on test set: 0.9780 , average accuracy on test set: 0.9817\n",
      "Training models with 150 samples, replicate #3\n",
      "training knn. fitting model. score on test set: 0.9780 , average accuracy on test set: 0.9796\n",
      "Training models with 150 samples, replicate #4\n",
      "training knn. fitting model. score on test set: 0.9900 , average accuracy on test set: 0.9885\n",
      "Training models with 150 samples, replicate #5\n",
      "training knn. fitting model. score on test set: 0.9660 , average accuracy on test set: 0.9646\n",
      "Training models with 150 samples, replicate #6\n",
      "training knn. fitting model. score on test set: 0.9740 , average accuracy on test set: 0.9756\n",
      "Training models with 150 samples, replicate #7\n",
      "training knn. fitting model. score on test set: 0.9800 , average accuracy on test set: 0.9804\n",
      "Training models with 150 samples, replicate #8\n",
      "training knn. fitting model. score on test set: 0.9880 , average accuracy on test set: 0.9856\n",
      "Training models with 150 samples, replicate #9\n",
      "training knn. fitting model. score on test set: 0.9300 , average accuracy on test set: 0.9209\n",
      "Training models with 200 samples, replicate #0\n",
      "training knn. fitting model. score on test set: 0.9880 , average accuracy on test set: 0.9877\n",
      "Training models with 200 samples, replicate #1\n",
      "training knn. fitting model. score on test set: 0.9840 , average accuracy on test set: 0.9779\n",
      "Training models with 200 samples, replicate #2\n",
      "training knn. fitting model. score on test set: 0.9860 , average accuracy on test set: 0.9828\n",
      "Training models with 200 samples, replicate #3\n",
      "training knn. fitting model. score on test set: 0.9560 , average accuracy on test set: 0.9397\n",
      "Training models with 200 samples, replicate #4\n",
      "training knn. fitting model. score on test set: 0.9960 , average accuracy on test set: 0.9964\n",
      "Training models with 200 samples, replicate #5\n",
      "training knn. fitting model. score on test set: 0.9560 , average accuracy on test set: 0.9475\n",
      "Training models with 200 samples, replicate #6\n",
      "training knn. fitting model. score on test set: 0.9880 , average accuracy on test set: 0.9836\n",
      "Training models with 200 samples, replicate #7\n",
      "training knn. fitting model. score on test set: 0.9600 , average accuracy on test set: 0.9511\n",
      "Training models with 200 samples, replicate #8\n",
      "training knn. fitting model. score on test set: 0.9660 , average accuracy on test set: 0.9584\n",
      "Training models with 200 samples, replicate #9\n",
      "training knn. fitting model. score on test set: 0.9800 , average accuracy on test set: 0.9824\n"
     ]
    }
   ],
   "source": [
    "hvc.select('gy6or6_autolabel.example.select.knn.config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Using the fit model, **Predict** labels for unlabeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In a text editor, open `gy6or6_autolabel.example.knn.predict.config.yml`\n",
    "2. On the line that says `model_meta_file:`, after the colon, paste the name of a meta file from the `select` output. The name will have a format like `summary_file_bird_ID_date`.\n",
    "3. Below the line that says `data_dirs:`, after the dash, add the path to the other folder of data that you downloaded.\n",
    "\n",
    "Then run the following code in the cell below.\n",
    "```Python\n",
    "# 6. **Predict** labels for unlabeled data using the fit model.\n",
    "hvc.predict('gy6or6_autolabel.example.predict.knn.config.yml')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/Documents/repositories/talks_and_teaching/hybrid-vocal-classifier-tutorial/select_output_171205_193932/knn_k4\n"
     ]
    }
   ],
   "source": [
    "cd select_output_171205_193932/knn_k4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_100samples_replicate0.meta   knn_200samples_replicate0.meta\r\n",
      "knn_100samples_replicate0.model  knn_200samples_replicate0.model\r\n",
      "knn_100samples_replicate1.meta   knn_200samples_replicate1.meta\r\n",
      "knn_100samples_replicate1.model  knn_200samples_replicate1.model\r\n",
      "knn_100samples_replicate2.meta   knn_200samples_replicate2.meta\r\n",
      "knn_100samples_replicate2.model  knn_200samples_replicate2.model\r\n",
      "knn_100samples_replicate3.meta   knn_200samples_replicate3.meta\r\n",
      "knn_100samples_replicate3.model  knn_200samples_replicate3.model\r\n",
      "knn_100samples_replicate4.meta   knn_200samples_replicate4.meta\r\n",
      "knn_100samples_replicate4.model  knn_200samples_replicate4.model\r\n",
      "knn_100samples_replicate5.meta   knn_200samples_replicate5.meta\r\n",
      "knn_100samples_replicate5.model  knn_200samples_replicate5.model\r\n",
      "knn_100samples_replicate6.meta   knn_200samples_replicate6.meta\r\n",
      "knn_100samples_replicate6.model  knn_200samples_replicate6.model\r\n",
      "knn_100samples_replicate7.meta   knn_200samples_replicate7.meta\r\n",
      "knn_100samples_replicate7.model  knn_200samples_replicate7.model\r\n",
      "knn_100samples_replicate8.meta   knn_200samples_replicate8.meta\r\n",
      "knn_100samples_replicate8.model  knn_200samples_replicate8.model\r\n",
      "knn_100samples_replicate9.meta   knn_200samples_replicate9.meta\r\n",
      "knn_100samples_replicate9.model  knn_200samples_replicate9.model\r\n",
      "knn_150samples_replicate0.meta   knn_50samples_replicate0.meta\r\n",
      "knn_150samples_replicate0.model  knn_50samples_replicate0.model\r\n",
      "knn_150samples_replicate1.meta   knn_50samples_replicate1.meta\r\n",
      "knn_150samples_replicate1.model  knn_50samples_replicate1.model\r\n",
      "knn_150samples_replicate2.meta   knn_50samples_replicate2.meta\r\n",
      "knn_150samples_replicate2.model  knn_50samples_replicate2.model\r\n",
      "knn_150samples_replicate3.meta   knn_50samples_replicate3.meta\r\n",
      "knn_150samples_replicate3.model  knn_50samples_replicate3.model\r\n",
      "knn_150samples_replicate4.meta   knn_50samples_replicate4.meta\r\n",
      "knn_150samples_replicate4.model  knn_50samples_replicate4.model\r\n",
      "knn_150samples_replicate5.meta   knn_50samples_replicate5.meta\r\n",
      "knn_150samples_replicate5.model  knn_50samples_replicate5.model\r\n",
      "knn_150samples_replicate6.meta   knn_50samples_replicate6.meta\r\n",
      "knn_150samples_replicate6.model  knn_50samples_replicate6.model\r\n",
      "knn_150samples_replicate7.meta   knn_50samples_replicate7.meta\r\n",
      "knn_150samples_replicate7.model  knn_50samples_replicate7.model\r\n",
      "knn_150samples_replicate8.meta   knn_50samples_replicate8.meta\r\n",
      "knn_150samples_replicate8.model  knn_50samples_replicate8.model\r\n",
      "knn_150samples_replicate9.meta   knn_50samples_replicate9.meta\r\n",
      "knn_150samples_replicate9.model  knn_50samples_replicate9.model\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ildefonso/Documents/repositories/talks_and_teaching/hybrid-vocal-classifier-tutorial\n"
     ]
    }
   ],
   "source": [
    "cd hybrid-vocal-classifier-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed predict config\n",
      "Changing to data directory: /home/ildefonso/Documents/data/gy6or6/032612\n",
      "Processing audio file 1 of 39.\n",
      "Processing audio file 2 of 39.\n",
      "Processing audio file 3 of 39.\n",
      "Processing audio file 4 of 39.\n",
      "Processing audio file 5 of 39.\n",
      "Processing audio file 6 of 39.\n",
      "Processing audio file 7 of 39.\n",
      "Processing audio file 8 of 39.\n",
      "Processing audio file 9 of 39.\n",
      "Processing audio file 10 of 39.\n",
      "Processing audio file 11 of 39.\n",
      "Processing audio file 12 of 39.\n",
      "Processing audio file 13 of 39.\n",
      "Processing audio file 14 of 39.\n",
      "Processing audio file 15 of 39.\n",
      "Processing audio file 16 of 39.\n",
      "Processing audio file 17 of 39.\n",
      "Processing audio file 18 of 39.\n",
      "Processing audio file 19 of 39.\n",
      "Processing audio file 20 of 39.\n",
      "Processing audio file 21 of 39.\n",
      "Processing audio file 22 of 39.\n",
      "Processing audio file 23 of 39.\n",
      "Processing audio file 24 of 39.\n",
      "Processing audio file 25 of 39.\n",
      "Processing audio file 26 of 39.\n",
      "Processing audio file 27 of 39.\n",
      "Processing audio file 28 of 39.\n",
      "Processing audio file 29 of 39.\n",
      "Processing audio file 30 of 39.\n",
      "Processing audio file 31 of 39.\n",
      "Processing audio file 32 of 39.\n",
      "Processing audio file 33 of 39.\n",
      "Processing audio file 34 of 39.\n",
      "Processing audio file 35 of 39.\n",
      "Processing audio file 36 of 39.\n",
      "Processing audio file 37 of 39.\n",
      "Processing audio file 38 of 39.\n",
      "Processing audio file 39 of 39.\n",
      "predicting labels for features in file: features_from_032612_created_171206_004609\n",
      "converting to .not.mat files\n"
     ]
    }
   ],
   "source": [
    "hvc.predict('gy6or6_autolabel.example.predict.knn.config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have auto-labeled an entire day's worth of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
